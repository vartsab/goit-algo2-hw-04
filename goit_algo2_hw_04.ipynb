{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OkI_403t2_Mj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. –ë–∞–∑–æ–≤–∏–π –æ–ø–∏—Å –∫–ª–∞—Å—ñ–≤ Trie —Ç–∞ TrieNode —ñ–∑ –ª–µ–∫—Ü—ñ—ó"
      ],
      "metadata": {
        "id": "OkI_403t2_Mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qgQjnNTQzThc"
      },
      "outputs": [],
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.value = None\n",
        "\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "        self.size = 0\n",
        "\n",
        "    def put(self, key, value=None):\n",
        "        if not isinstance(key, str) or not key:\n",
        "            raise TypeError(f\"Illegal argument for put: key = {key} must be a non-empty string\")\n",
        "\n",
        "        current = self.root\n",
        "        for char in key:\n",
        "            if char not in current.children:\n",
        "                current.children[char] = TrieNode()\n",
        "            current = current.children[char]\n",
        "        if current.value is None:\n",
        "            self.size += 1\n",
        "        current.value = value\n",
        "\n",
        "    def get(self, key):\n",
        "        if not isinstance(key, str) or not key:\n",
        "            raise TypeError(f\"Illegal argument for get: key = {key} must be a non-empty string\")\n",
        "\n",
        "        current = self.root\n",
        "        for char in key:\n",
        "            if char not in current.children:\n",
        "                return None\n",
        "            current = current.children[char]\n",
        "        return current.value\n",
        "\n",
        "    def delete(self, key):\n",
        "        if not isinstance(key, str) or not key:\n",
        "            raise TypeError(f\"Illegal argument for delete: key = {key} must be a non-empty string\")\n",
        "\n",
        "        def _delete(node, key, depth):\n",
        "            if depth == len(key):\n",
        "                if node.value is not None:\n",
        "                    node.value = None\n",
        "                    self.size -= 1\n",
        "                    return len(node.children) == 0\n",
        "                return False\n",
        "\n",
        "            char = key[depth]\n",
        "            if char in node.children:\n",
        "                should_delete = _delete(node.children[char], key, depth + 1)\n",
        "                if should_delete:\n",
        "                    del node.children[char]\n",
        "                    return len(node.children) == 0 and node.value is None\n",
        "            return False\n",
        "\n",
        "        return _delete(self.root, key, 0)\n",
        "\n",
        "    def is_empty(self):\n",
        "        return self.size == 0\n",
        "\n",
        "    def longest_prefix_of(self, s):\n",
        "        if not isinstance(s, str) or not s:\n",
        "            raise TypeError(f\"Illegal argument for longestPrefixOf: s = {s} must be a non-empty string\")\n",
        "\n",
        "        current = self.root\n",
        "        longest_prefix = \"\"\n",
        "        current_prefix = \"\"\n",
        "        for char in s:\n",
        "            if char in current.children:\n",
        "                current = current.children[char]\n",
        "                current_prefix += char\n",
        "                if current.value is not None:\n",
        "                    longest_prefix = current_prefix\n",
        "            else:\n",
        "                break\n",
        "        return longest_prefix\n",
        "\n",
        "    def keys_with_prefix(self, prefix):\n",
        "        if not isinstance(prefix, str):\n",
        "            raise TypeError(f\"Illegal argument for keysWithPrefix: prefix = {prefix} must be a string\")\n",
        "\n",
        "        current = self.root\n",
        "        for char in prefix:\n",
        "            if char not in current.children:\n",
        "                return []\n",
        "            current = current.children[char]\n",
        "\n",
        "        result = []\n",
        "        self._collect(current, list(prefix), result)\n",
        "        return result\n",
        "\n",
        "    def _collect(self, node, path, result):\n",
        "        if node.value is not None:\n",
        "            result.append(\"\".join(path))\n",
        "        for char, next_node in node.children.items():\n",
        "            path.append(char)\n",
        "            self._collect(next_node, path, result)\n",
        "            path.pop()\n",
        "\n",
        "    def keys(self):\n",
        "        result = []\n",
        "        self._collect(self.root, [], result)\n",
        "        return result\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## –ó–∞–¥–∞—á–∞ 1. –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—É –ø—Ä–µ—Ñ—ñ–∫—Å–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞"
      ],
      "metadata": {
        "id": "0yuKVaM61cld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –†–µ–∞–ª—ñ–∑—É–π—Ç–µ –¥–≤–∞ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –º–µ—Ç–æ–¥–∏ –¥–ª—è –∫–ª–∞—Å—É Trie:\n",
        "\n",
        "- `count_words_with_suffix(pattern)` –¥–ª—è –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å–ª—ñ–≤, —â–æ –∑–∞–∫—ñ–Ω—á—É—é—Ç—å—Å—è –∑–∞–¥–∞–Ω–∏–º —à–∞–±–ª–æ–Ω–æ–º;\n",
        "- `has_prefix(prefix)` –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Å–ª—ñ–≤ —ñ–∑ –∑–∞–¥–∞–Ω–∏–º –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º.\n",
        "\n",
        "\n",
        "#### –¢–µ—Ö–Ω—ñ—á–Ω—ñ —É–º–æ–≤–∏\n",
        "\n",
        "- –ö–ª–∞—Å Homework –º–∞—î —É—Å–ø–∞–¥–∫–æ–≤—É–≤–∞—Ç–∏ –±–∞–∑–æ–≤–∏–π –∫–ª–∞—Å `Trie`.\n",
        "- –ú–µ—Ç–æ–¥–∏ –ø–æ–≤–∏–Ω–Ω—ñ –æ–ø—Ä–∞—Ü—å–æ–≤—É–≤–∞—Ç–∏ –ø–æ–º–∏–ª–∫–∏ –≤–≤–µ–¥–µ–Ω–Ω—è –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏—Ö –¥–∞–Ω–∏—Ö.\n",
        "- –í—Ö—ñ–¥–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –æ–±–æ—Ö –º–µ—Ç–æ–¥—ñ–≤ –º–∞—é—Ç—å –±—É—Ç–∏ —Ä—è–¥–∫–∞–º–∏.\n",
        "- –ú–µ—Ç–æ–¥ `count_words_with_suffix` –º–∞—î –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ —Ü—ñ–ª–µ —á–∏—Å–ª–æ.\n",
        "- –ú–µ—Ç–æ–¥ `has_prefix` –º–∞—î –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ –±—É–ª–µ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è."
      ],
      "metadata": {
        "id": "gCR972fz3Z5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Homework(Trie):\n",
        "    def count_words_with_suffix(self, pattern) -> int:\n",
        "        if not isinstance(pattern, str):\n",
        "            raise TypeError(\"The pattern must be a string\")\n",
        "        return sum(word.endswith(pattern) for word in self.keys())\n",
        "\n",
        "    def has_prefix(self, prefix) -> bool:\n",
        "        if not isinstance(prefix, str):\n",
        "            raise TypeError(\"The prefix must be a string\")\n",
        "        return len(self.keys_with_prefix(prefix)) > 0"
      ],
      "metadata": {
        "id": "C6QoHwhnziGc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ü—Ä–æ—Ç–µ—Å—Ç—É—î–º–æ, —â–æ –≤–∏–π—à–ª–æ"
      ],
      "metadata": {
        "id": "NTXsWNRR1iok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trie = Homework()\n",
        "words = [\"apple\", \"application\", \"banana\", \"cat\"]\n",
        "for i, word in enumerate(words):\n",
        "    trie.put(word, i)\n",
        "\n",
        "assert trie.count_words_with_suffix(\"e\") == 1\n",
        "assert trie.count_words_with_suffix(\"ion\") == 1\n",
        "assert trie.count_words_with_suffix(\"a\") == 1\n",
        "assert trie.count_words_with_suffix(\"at\") == 1\n",
        "\n",
        "assert trie.has_prefix(\"app\") is True\n",
        "assert trie.has_prefix(\"bat\") is False\n",
        "assert trie.has_prefix(\"ban\") is True\n",
        "assert trie.has_prefix(\"ca\") is True"
      ],
      "metadata": {
        "id": "jLRwbpVmzomm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö–æ–¥ –Ω–µ –≤–∏–¥–∞–≤ –ø–æ–º–∏–ª–æ–∫, —Ç–æ–±—Ç–æ —Ç–µ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω–æ, –∞–ª–µ –ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫ –≤–∏–≤–µ–¥–µ–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏"
      ],
      "metadata": {
        "id": "m00Z2aGe1yBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Task 1 ‚Äî count_words_with_suffix:\")\n",
        "print(\"Suffix 'e':\", trie.count_words_with_suffix(\"e\"))           # 1\n",
        "print(\"Suffix 'ion':\", trie.count_words_with_suffix(\"ion\"))       # 1\n",
        "print(\"Suffix 'a':\", trie.count_words_with_suffix(\"a\"))           # 1\n",
        "print(\"Suffix 'at':\", trie.count_words_with_suffix(\"at\"))         # 1\n",
        "\n",
        "print(\"\\nTask 1 ‚Äî has_prefix:\")\n",
        "print(\"Prefix 'app':\", trie.has_prefix(\"app\"))       # True\n",
        "print(\"Prefix 'bat':\", trie.has_prefix(\"bat\"))       # False\n",
        "print(\"Prefix 'ban':\", trie.has_prefix(\"ban\"))       # True\n",
        "print(\"Prefix 'ca':\", trie.has_prefix(\"ca\"))         # True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3au6MgsN1vzG",
        "outputId": "72a5d105-3f4b-43a9-befe-e6b27e714e36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 ‚Äî count_words_with_suffix:\n",
            "Suffix 'e': 1\n",
            "Suffix 'ion': 1\n",
            "Suffix 'a': 1\n",
            "Suffix 'at': 1\n",
            "\n",
            "Task 1 ‚Äî has_prefix:\n",
            "Prefix 'app': True\n",
            "Prefix 'bat': False\n",
            "Prefix 'ban': True\n",
            "Prefix 'ca': True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚õ≥ –ú–µ—Ç–æ–¥ count_words_with_suffix –ø–æ–≤–µ—Ä—Ç–∞—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤, —â–æ –∑–∞–∫—ñ–Ω—á—É—é—Ç—å—Å—è –Ω–∞ –∑–∞–¥–∞–Ω–∏–π pattern. –ó–∞ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ —Å–ª—ñ–≤ –ø–æ–≤–µ—Ä—Ç–∞—î 0. –í—Ä–∞—Ö–æ–≤—É—î —Ä–µ–≥—ñ—Å—Ç—Ä —Å–∏–º–≤–æ–ª—ñ–≤. :\n",
        "\n",
        "‚úÖ –ú–µ—Ç–æ–¥ has_prefix –ø–æ–≤–µ—Ä—Ç–∞—î True, —è–∫—â–æ —ñ—Å–Ω—É—î —Ö–æ—á–∞ –± –æ–¥–Ω–µ —Å–ª–æ–≤–æ —ñ–∑ –∑–∞–¥–∞–Ω–∏–º –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º. –ü–æ–≤–µ—Ä—Ç–∞—î False, —è–∫—â–æ —Ç–∞–∫–∏—Ö —Å–ª—ñ–≤ –Ω–µ–º–∞—î. –í—Ä–∞—Ö–æ–≤—É—î —Ä–µ–≥—ñ—Å—Ç—Ä —Å–∏–º–≤–æ–ª—ñ–≤.\n",
        "\n",
        "ü¶æ –ö–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —É—Å—ñ —Ç–µ—Å—Ç–∏.\n",
        "\n",
        "‚ùï –û–±—Ä–æ–±–ª—è—é—Ç—å—Å—è –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ.\n",
        "\n",
        "üëç –ú–µ—Ç–æ–¥–∏ –ø—Ä–∞—Ü—é—é—Ç—å –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–∏—Ö."
      ],
      "metadata": {
        "id": "28ee9P1q4VRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## –ó–∞–¥–∞—á–∞ 2. –ü–æ—à—É–∫ –Ω–∞–π–¥–æ–≤—à–æ–≥–æ —Å–ø—ñ–ª—å–Ω–æ–≥–æ –ø—Ä–µ—Ñ—ñ–∫—Å–∞"
      ],
      "metadata": {
        "id": "vLkyzOQu1_zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### –°—Ç–≤–æ—Ä—ñ—Ç—å –∫–ª–∞—Å `LongestCommonWord`, —è–∫–∏–π –Ω–∞—Å–ª—ñ–¥—É—î –∫–ª–∞—Å Trie, —Ç–∞ —Ä–µ–∞–ª—ñ–∑—É–π—Ç–µ –º–µ—Ç–æ–¥ find_longest_common_word, —è–∫–∏–π –∑–Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–∞–π–¥–æ–≤—à–∏–π —Å–ø—ñ–ª—å–Ω–∏–π –ø—Ä–µ—Ñ—ñ–∫—Å –¥–ª—è –≤—Å—ñ—Ö —Å–ª—ñ–≤ —É –≤—Ö—ñ–¥–Ω–æ–º—É –º–∞—Å–∏–≤—ñ —Ä—è–¥–∫—ñ–≤ strings.\n",
        "\n",
        "–¢–µ—Ö–Ω—ñ—á–Ω—ñ —É–º–æ–≤–∏\n",
        "\n",
        "- –ö–ª–∞—Å LongestCommonWord –º–∞—î —É—Å–ø–∞–¥–∫–æ–≤—É–≤–∞—Ç–∏ Trie.\n",
        "- –í—Ö—ñ–¥–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä –º–µ—Ç–æ–¥—É find_longest_common_word, strings ‚Äî –º–∞—Å–∏–≤ —Ä—è–¥–∫—ñ–≤.\n",
        "- –ú–µ—Ç–æ–¥ find_longest_common_word –º–∞—î –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ —Ä—è–¥–æ–∫ ‚Äî –Ω–∞–π–¥–æ–≤—à–∏–π —Å–ø—ñ–ª—å–Ω–∏–π –ø—Ä–µ—Ñ—ñ–∫—Å.\n",
        "- –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è ‚Äî O(S), –¥–µ S ‚Äî —Å—É–º–∞—Ä–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –≤—Å—ñ—Ö —Ä—è–¥–∫—ñ–≤."
      ],
      "metadata": {
        "id": "nfAa4g8c32yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LongestCommonWord(Trie):\n",
        "    def find_longest_common_word(self, strings) -> str:\n",
        "        if not isinstance(strings, list) or not all(isinstance(s, str) for s in strings):\n",
        "            raise TypeError(\"Input must be a list of strings\")\n",
        "        if not strings:\n",
        "            return \"\"\n",
        "        for i, word in enumerate(strings):\n",
        "            self.put(word, i)\n",
        "\n",
        "        current = self.root\n",
        "        prefix = []\n",
        "        while current and len(current.children) == 1 and current.value is None:\n",
        "            char = next(iter(current.children))\n",
        "            prefix.append(char)\n",
        "            current = current.children[char]\n",
        "        return \"\".join(prefix)"
      ],
      "metadata": {
        "id": "As25fJ8Pzive"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ü—Ä–æ—Ç–µ—Å—Ç—É—î–º–æ, —á–∏ –≤–æ–Ω–∞ –ø—Ä–∞—Ü—é—î üé†"
      ],
      "metadata": {
        "id": "L5SGTWMK2TTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trie = LongestCommonWord()\n",
        "strings = [\"flower\", \"flow\", \"flight\"]\n",
        "assert trie.find_longest_common_word(strings) == \"fl\"\n",
        "print(strings, \"‚Üí\", trie.find_longest_common_word(strings))       # \"fl\"\n",
        "\n",
        "trie = LongestCommonWord()\n",
        "strings = [\"interspecies\", \"interstellar\", \"interstate\"]\n",
        "assert trie.find_longest_common_word(strings) == \"inters\"\n",
        "print(strings, \"‚Üí\", trie.find_longest_common_word(strings))       # \"inters\"\n",
        "\n",
        "trie = LongestCommonWord()\n",
        "strings = [\"dog\", \"racecar\", \"car\"]\n",
        "assert trie.find_longest_common_word(strings) == \"\"\n",
        "print(strings, \"‚Üí\", trie.find_longest_common_word(strings))       # \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWA8kijnzpi9",
        "outputId": "b7d40afd-2ada-4223-a29d-e5b1e63e6b52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['flower', 'flow', 'flight'] ‚Üí fl\n",
            "['interspecies', 'interstellar', 'interstate'] ‚Üí inters\n",
            "['dog', 'racecar', 'car'] ‚Üí \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú–µ—Ç–æ–¥ find_longest_common_word ‚úå\n",
        "  \n",
        "ü™ì –ø–æ–≤–µ—Ä—Ç–∞—î –Ω–∞–π–¥–æ–≤—à–∏–π –ø—Ä–µ—Ñ—ñ–∫—Å, —Å–ø—ñ–ª—å–Ω–∏–π –¥–ª—è –≤—Å—ñ—Ö —Å–ª—ñ–≤,\n",
        "\n",
        "üëÄ –ø–æ–≤–µ—Ä—Ç–∞—î –ø—É—Å—Ç–∏–π —Ä—è–¥–æ–∫, —è–∫—â–æ —Å–ø—ñ–ª—å–Ω–æ–≥–æ –ø—Ä–µ—Ñ—ñ–∫—Å–∞ –Ω–µ–º–∞—î,\n",
        "\n",
        "‚ùé –∫–æ—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–æ–±–ª—è—î –ø–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤ –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ."
      ],
      "metadata": {
        "id": "hRu07Dpb6Uew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úå –ö–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —É—Å—ñ —Ç–µ—Å—Ç–∏ üíÉ"
      ],
      "metadata": {
        "id": "Ct9U8D_L2bFC"
      }
    }
  ]
}